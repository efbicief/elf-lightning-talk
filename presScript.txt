Hi! I'm Felix, I'm a second-year Computer Systems Engineering student, and today I want to share with you ... How to code-golf an ELF executable. For those of you who don't know, an ELF executable is your standard binary executable on Linux, roughly equivalent to an EXE on Windows, and code-golfing is the act of creating a program containing the smallest amount of bytes.

First of all I'm going to introduce you to a tool you may or may not have used called GCC, or the GNU C Compiler. It's most used to compile C code into an ELF executable, which you can actually run on your computer. One thing it uses to do this is libc, the C standard library, which amongst other things contains functions which allow your C programs to make system calls. GCC also acts as a frontend to the GNU linker, ld, which takes bytecode object files, and actually turns them into an executable.

So GCC itself can take a file containing C code, or a bytecode .o object file generated by another program, such as an assembler (this will be important later). It takes these files, and transforms them into object files, whilst using libc to allow the program to make libc system calls. It then passes the resulting object file or files to the linker, which stitches together the bytecode into an executable.

But back to code-golfing - if we want to create the smallest possible executable, we first need to create the smallest possible C program. About the simplest you can get is one that returns 0 or 1, but since these are already taken, I'm going to use a program that returns 2.

<demo>
So here in VSCode I have this program, and if we compile it, run it, and print the return value, we can see that our program returns 2. I can run this command to see how big the resulting executable, and we can see that it is X bytes. Now, you're probably thinking that that's quite a small file, but I'm thinking "Why do we need X bytes to just return the number 2"?
</demo>

Luckily, GCC takes some flags designed to optimise our executable - we can strip unnessecary headers with -s, and tell it to make some generic optimisations with -O3.

<demo>
Now, if we compile like so, we can see that out file is now X bytes. An improvement for sure, but I think we can do better.
</demo>

How else can we optimise GCC? Well, one thing we can do is stop using C. If you remember from earlier, we can actually just pass an object file from an assembler into GCC, and in theory this should reduce some of the overhead we get from C.

So, if we write some assembly that does what we want to do, return the number 2, we get this. If you haven't done any assembly before, don't worry - I'll try to explain. We have this jump point main, which corresponds to the main entry point in libc that GCC looks for when compiling our code. Next, we move the number 2 into our 64-bit rax register, which holds out return value. Finally, we call ret, which just returns the value in rax to the parent process.

<demo>
If we take this assembly and assemble it into bytecode, I'm using the Netwide Assembler nasm, so if we take this bytecode and link it in with libc with GCC, then we get an executable, and as you can see, it returns 2. Looking at the size of this executable, we have improved again, but there is still much more data here than I would expect you to need just to return a number.
</demo>

We need to ask ourselves the question, where does this overhead come from? And why do we still need to use libc in our program? Well, what we can actually do is stop using libc.

Instead of using the libc entry point main, we can use a symbol from the linker ld called _start. This is actually called by libc's start (no underscore) function, but just calling this ourselves skips the setup that has to be done to use libc functions, which for our purporses is completely unnessecary. The other thing that we can't use anymore is our ret function - instead, we have to make a Linux system call to end our program. In short, to make a system call, we need 2 things - a system call ID, which specifies the actual function that we want the Linux kernel to do for us, and any parameters it needs to do that. The system call ID is stored in our rax register - in this case, the standard ID for exiting a program is 1. We store our parameter, the value that we want the program to return when exiting, in rbx, 2. We then start the system call with this int 0x80 command. Note that this command will only trigger a system call on Linux - we've now left behind any ounce of portability that libc gives us normally.

<demo>
To run this code without using libc, we assemble this like before, but this time when we pass it to GCC, we pass this -nostdlib flag which will stop gcc from linking in libc. Now, we can see that we have yet another smaller file.
</demo>

Of course though, we can improve. At the moment, we are using rax and rbx, which are both 64-bit registers. How about we instead write to al and bl, which are the corresponding 8 least significant bits. Whilst we're here, we can use a smaller instruction to set al to 1, by xoring it with itself, and then incrementing the value.

<demo>
When we run this, we see that our executable... is no smaller. It might seem like something has gone wrong, until we realise that this whole time we've been using this -O3 optimisation flag, which has been optimising away our 64-bit registers this whole time without us knowing.
</demo>

Now that we've taken these steps to optimise our program, we can take the biggest step in optimising GCC... stop using GCC. If you think back to earlier, GCC consists of a compiler, which generates bytecode using libc, and a linker. Now that we're not using libc at all, why don't we just pass out assembler bytecode straight to the linker ourselves?

<demo>
If we take our object file from earlier and pass it straight to the linker, we can see that our file is much smaller! However, the question still remains - how can we code-golf this even more? If we take a look at the executable that we're running in a hex editor, we can see that it's mosty full of zeroes.
</demo>

In fact, in this particular instance, it is 86.4% zeroed padding space. Why do we have this?

It's actually to do with the section header table, which is a part of the ELF standard format.

If we look at the structure of an ELF executable, we can see that it is made of a number of parts - headers, tables, and program segments. The program header table is used during execution to locate certain parts of our code, such as the entry point. The section header table has a similar use, except it is used by the compiler and linker. Unfortunately, we can't stop our assembler from including this table, and since it's usually a comparatively small and insignificant part of the executable, our linker doesn't bother to remove it from the executable. Therefore, if we want to make our executable smaller, we're going to have to do it ourselves.

This code looks... intimidating. However, you don't actually have to understand most of it. Most of it is defining the ELF header and program header table, and defining our entry point _start, which is luckily also the default name in the ELF standard. Then at the bottom here, we just have the exact same code as before.

<demo>
If we then take this code, and instead of assembling it in the usual way, we specify our output as a binary format. We can then execute this output directly, and as you can see, it still returns 2 without any problems! Finally, if we find out how big our executable is, we get... a glorious 128 bytes. This is the size of the standard ELF header, plus our code. It is beautiful.
</demo>

And this is the hex dump of our executable. Beautiful. You might now be asking whether we can reduce this any further - within the bounds of the ELF standard, no. However, there are some tricks we can play around with to do with how Linux processes these files. These are tricks that we unfortunately don't have time for. 

If you're at all interested in this topic, shoot me a message and talk to me about it! I have been Felix, this is my website and Discord, thank you!